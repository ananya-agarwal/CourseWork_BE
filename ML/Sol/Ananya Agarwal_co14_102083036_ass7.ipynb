{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"E:/5th sem/ML/lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   SepalLength  150 non-null    float64\n",
      " 1   SepalWidth   150 non-null    float64\n",
      " 2   PetalLength  150 non-null    float64\n",
      " 3   PetalWidth   150 non-null    float64\n",
      " 4   Species      150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "0            5.1         3.5          1.4         0.2\n",
      "1            4.9         3.0          1.4         0.2\n",
      "2            4.7         3.2          1.3         0.2\n",
      "3            4.6         3.1          1.5         0.2\n",
      "4            5.0         3.6          1.4         0.2\n",
      "..           ...         ...          ...         ...\n",
      "145          6.7         3.0          5.2         2.3\n",
      "146          6.3         2.5          5.0         1.9\n",
      "147          6.5         3.0          5.2         2.0\n",
      "148          6.2         3.4          5.4         2.3\n",
      "149          5.9         3.0          5.1         1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "X=df.iloc[:,:4]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: Species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "Y=df.iloc[:,4]\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#Encode target labels with value between 0 and n_classes-1 i.e. 0 for setosa, 1 for versicolor, 2 for verginica\n",
    "#This transformer should be used to encode target values, i.e. y, and not the input X\n",
    "\n",
    "y = le.fit_transform(Y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "#fixing 30 percent data as testing data\n",
    "#random_state = any integer se fix hogaya hai ki yahi vala 30 prcnt data hi aaye as testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for Naive Bayes\n",
      " [[16  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  0 11]]\n",
      "accuracy_Naive Bayes: 1.000\n",
      "precision_Naive Bayes: 1.000\n",
      "recall_Naive Bayes: 1.000\n",
      "f1-score_Naive Bayes : 1.000\n",
      "[16. 18. 11.]\n",
      "[0. 0. 0.]\n",
      "TPR:  [1. 1. 1.]\n",
      "TNR:  [1. 1. 1.]\n",
      "FPR:  [0. 0. 0.]\n",
      "FNR:  [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "Y_pred = gaussian.predict(X_test) \n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score ,precision_score,recall_score,f1_score,make_scorer\n",
    "\n",
    "cm = confusion_matrix(y_test, Y_pred)\n",
    "accuracy = accuracy_score(y_test,Y_pred)\n",
    "precision =precision_score(y_test, Y_pred,average='micro')\n",
    "recall =  recall_score(y_test, Y_pred,average='micro')\n",
    "f1 = f1_score(y_test,Y_pred,average='micro')\n",
    "\n",
    "print('Confusion matrix for Naive Bayes\\n',cm)\n",
    "print('accuracy_Naive Bayes: %.3f' %accuracy)\n",
    "print('precision_Naive Bayes: %.3f' %precision)\n",
    "print('recall_Naive Bayes: %.3f' %recall)\n",
    "print('f1-score_Naive Bayes : %.3f' %f1)\n",
    "\n",
    "# '%d' %(number) number ki value has gone to d and vahan modification hoke display hui\n",
    "\n",
    "\n",
    "TP = np.diag(cm) #Extract a diagonal\n",
    "FP = cm.sum(axis=0) - np.diag(cm) #axis = 0 means rows\n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "print(TP)\n",
    "print(FN)\n",
    "\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP) \n",
    "FPR = FP/(FP+TN)\n",
    "FNR = FN/(TP+FN)\n",
    "\n",
    "print(\"TPR: \",TPR)\n",
    "print(\"TNR: \",TNR)\n",
    "print(\"FPR: \",FPR)\n",
    "print(\"FNR: \",FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 2 (can leave it)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,Y_pred))\n",
    "\n",
    "#The support is the number of occurrences of each class in y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
